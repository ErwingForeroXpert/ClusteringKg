{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy==1.22.3\n",
    "# pandas==1.4.2\n",
    "# python-dateutil==2.8.2\n",
    "# pytz==2022.1\n",
    "# pywin32==303\n",
    "# pyxlsb==1.0.9\n",
    "# six==1.16.0\n",
    "# xlwings==0.27.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required modules\n",
    "import os\n",
    "import re\n",
    "import asyncio\n",
    "import functools\n",
    "import pandas as pd\n",
    "\n",
    "from cluster.cluster import Cluster\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from dataframes.dataframe_optimized import DataFrameOptimized\n",
    "from utils import constants as const, index as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_bases(sources: dict[str, str], files: list[str], cached_data: bool = False) -> 'tuple(list[str], list[DataFrameOptimized])':\n",
    "    \"\"\"Get DataFrames of sources\n",
    "\n",
    "    Args:\n",
    "        sources (dict[str, str]): dict of sources \n",
    "\n",
    "    Returns:\n",
    "        list[DataFrameOptimized]: [description]\n",
    "    \"\"\"\n",
    "    if cached_data is True:\n",
    "        #only for test with csv value - delete\n",
    "        bases = {f\"{file.split('.')[0]}\": DataFrameOptimized(pd.read_csv(os.path.join(const.ROOT_DIR, f\"files/temp/{file}\"))) for file in os.listdir(os.path.join(const.ROOT_DIR, f\"files/temp\"))}\n",
    "        bases[\"base_consulta_directa\"] = [bases.pop('base_consulta_directa_0')]\n",
    "        bases[\"base_consulta_indirecta\"] = [bases.pop('base_consulta_indirecta_0'), bases.pop('base_consulta_indirecta_1')]\n",
    "\n",
    "        return bases\n",
    "    else:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "\n",
    "            futures = []\n",
    "            keys = []\n",
    "\n",
    "            for key, source in sources.items():\n",
    "                path = files[key].split(\"|\") #list[base, ...] - key is a name of base\n",
    "                if len(path) == 1:\n",
    "                    path = path[0]\n",
    "                keys.append(key)\n",
    "                futures.append(loop.run_in_executor(executor, functools.partial(Cluster.preprocess_base, **{\"path\": path, \"properties\": source})))\n",
    "\n",
    "            results = await asyncio.gather(*futures)\n",
    "\n",
    "        for key, base in zip(keys, results): \n",
    "            if isinstance(base, (list, tuple)):\n",
    "                for idx in range(len(base)):\n",
    "                    base[idx].table.to_csv(f\"{os.path.join(const.ROOT_DIR, 'files/temp')}/{key}_{idx}.csv\", encoding=\"latin-1\", index = None)\n",
    "            else:\n",
    "                base.table.to_csv(f\"{os.path.join(const.ROOT_DIR, 'files/temp')}/{key}.csv\", encoding=\"latin-1\", index = None)\n",
    "\n",
    "        return dict(zip(keys, results))\n",
    "\n",
    "def get_predeterminated_files(_path: str):\n",
    "    \n",
    "        found = {\n",
    "            \"base_socios\": \"\",\n",
    "            \"base_coordenadas\": \"\",\n",
    "            \"base_universo_directa\": \"\",\n",
    "            \"base_universo_indirecta\": \"\",\n",
    "            \"base_consulta_directa\": \"\",\n",
    "            \"base_consulta_indirecta\": \"\"\n",
    "        }\n",
    "        for (dirpath, dirnames, filenames) in os.walk(_path):\n",
    "            for file in filenames:\n",
    "                if re.search(\"socio\", file, re.IGNORECASE):\n",
    "                    found[\"base_socios\"] = os.path.join(_path, file)\n",
    "                elif re.search(\"coord\", file, re.IGNORECASE):\n",
    "                    found[\"base_coordenadas\"] = os.path.join(_path, file)\n",
    "                elif re.search(r\"universo\\s+direc\", file, re.IGNORECASE):\n",
    "                    found[\"base_universo_directa\"] = os.path.join(_path, file)\n",
    "                elif re.search(r\"universo\\s+indirec\", file, re.IGNORECASE):\n",
    "                    found[\"base_universo_indirecta\"] = os.path.join(_path, file)\n",
    "\n",
    "            for dir in dirnames:\n",
    "                files = []\n",
    "                root_dir = os.path.join(_path, dir)\n",
    "                for _file in os.listdir(root_dir):\n",
    "                    files.append(os.path.normpath(os.path.join(root_dir, _file)))\n",
    "                if re.search(\"indirecta\", dir, re.IGNORECASE):\n",
    "                    found[\"base_consulta_indirecta\"] = \"|\".join(files)\n",
    "                elif re.search(\"directa\", dir, re.IGNORECASE):\n",
    "                    found[\"base_consulta_directa\"] = \"|\".join(files)\n",
    "        return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load configfile\n",
    "config = utils.get_config(os.path.join(const.ROOT_DIR, \"config.yml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "principal process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load config, paths and structure of files\n",
    "config = utils.get_config(os.path.join(const.ROOT_DIR, \"config.yml\"))\n",
    "files_found = get_predeterminated_files(os.path.join(const.ROOT_DIR, \"files/Bases\"))\n",
    "sources = config[\"sources\"]\n",
    "\n",
    "#actual event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "#get bases of data\n",
    "bases = loop.run_until_complete(get_bases(sources, files_found, cached_data=True))  \n",
    "\n",
    "#execute process to merge\n",
    "final_base = Cluster()\n",
    "loop.run_until_complete(final_base.merge_all(bases, config[\"order_base\"]))\n",
    "\n",
    "#save result\n",
    "final_base.table.to_csv(\"base_final.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f9411b5dc834ba136f323b80556c98fffceea74ee4cc78a826ac63306838f1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('ClusteringKg-7VG3ZJPS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
